{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39676dde-0f76-4b9c-80f2-e314e4c54c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "print(SparkContext._active_spark_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0665a510-e402-44b6-97ae-b3d154cf110f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è SparkSession –∏ JDBC –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ETL Star Schema Reports to ClickHouse\") \\\n",
    "    .config(\"spark.jars\", \"postgresql-42.6.0.jar,clickhouse-jdbc-0.4.6.jar\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# PostgreSQL\n",
    "pg_url   = \"jdbc:postgresql://postgres:5432/spark_db\"\n",
    "pg_props = {\n",
    "    \"user\": \"spark_user\",\n",
    "    \"password\": \"spark_password\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "# ClickHouse\n",
    "ch_url   = \"jdbc:clickhouse://clickhouse:8123/default\"\n",
    "ch_props = {\n",
    "    \"driver\":   \"com.clickhouse.jdbc.ClickHouseDriver\",\n",
    "    \"user\":     \"custom_user\",\n",
    "    \"password\": \"custom_password\",\n",
    "}\n",
    "\n",
    "print(\"‚úîÔ∏è SparkSession –∏ JDBC –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a685fac-1447-4b75-b24c-a66879166f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è –î–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "fact_sales    = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"fact_sales\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_products  = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_products\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_customers = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_customers\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_dates     = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_dates\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_stores    = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_stores\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_suppliers = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_suppliers\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_countries = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_countries\",\n",
    "    properties=pg_props\n",
    ")\n",
    "dim_cities    = spark.read.jdbc(\n",
    "    url=pg_url,\n",
    "    table=\"dim_cities\",\n",
    "    properties=pg_props\n",
    ")\n",
    "\n",
    "print(\"‚úîÔ∏è –î–∞–Ω–Ω—ã–µ –∏–∑ PostgreSQL –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "185d6895-8941-4a8e-8efc-969e4cf686e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è top10_products: 3 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è revenue_by_category: 2 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è rating_reviews: 3 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 3a: sales_by_product ‚Äî –±–∞–∑–æ–≤–∞—è –≤–∏—Ç—Ä–∏–Ω–∞\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "prod_metrics = (\n",
    "    fact_sales\n",
    "      .join(dim_products, \"product_id\")\n",
    "      .select(\"product_id\",\"product_name\",\"category_id\",\"quantity\",\"total_price\",\"rating\",\"reviews\")\n",
    ")\n",
    "\n",
    "# 1) –¢–æ–ø-10 —Å–∞–º—ã—Ö –ø—Ä–æ–¥–∞–≤–∞–µ–º—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤\n",
    "top10_products = (\n",
    "    prod_metrics\n",
    "      .groupBy(\"product_id\",\"product_name\")\n",
    "      .agg(F.sum(\"quantity\").alias(\"units_sold\"))\n",
    "      .orderBy(F.col(\"units_sold\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "# 2) –û–±—â–∞—è –≤—ã—Ä—É—á–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –ø—Ä–æ–¥—É–∫—Ç–æ–≤\n",
    "revenue_by_category = (\n",
    "    prod_metrics\n",
    "      .groupBy(\"category_id\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    ")\n",
    "\n",
    "# 3) –°—Ä–µ–¥–Ω–∏–π —Ä–µ–π—Ç–∏–Ω–≥ –∏ –∫–æ–ª-–≤–æ –æ—Ç–∑—ã–≤–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞\n",
    "rating_reviews = (\n",
    "    prod_metrics\n",
    "      .groupBy(\"product_id\",\"product_name\")\n",
    "      .agg(\n",
    "         F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "         F.sum(\"reviews\").alias(\"total_reviews\")\n",
    "      )\n",
    ")\n",
    "\n",
    "# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—Å–µ —Ç—Ä–∏ –≤ ClickHouse\n",
    "for tbl, df, order_cols in [\n",
    "    (\"top10_products\",      top10_products,      [\"units_sold\"]),\n",
    "    (\"revenue_by_category\", revenue_by_category, [\"category_id\"]),\n",
    "    (\"rating_reviews\",      rating_reviews,      [\"product_id\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "328a4d88-c770-4f1c-b7bc-df86efc081ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è top10_customers: 10 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è customers_by_country: 204 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è avg_check_per_customer: 10000 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 4a: sales_by_customer ‚Äî –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "# 1) –¢–æ–ø-10 –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –æ–±—â–µ–π —Å—É–º–º–µ –ø–æ–∫—É–ø–æ–∫\n",
    "top10_customers = (\n",
    "    fact_sales\n",
    "      .join(dim_customers, \"customer_id\")\n",
    "      .groupBy(\"customer_id\",\"first_name\",\"last_name\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"total_spent\"))\n",
    "      .orderBy(F.col(\"total_spent\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "# 2) –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º\n",
    "customers_by_country = (\n",
    "    fact_sales\n",
    "      .join(dim_customers, \"customer_id\")\n",
    "      .join(dim_countries, [\"country_id\"], \"left\")\n",
    "      .groupBy(\"country_name\")\n",
    "      .agg(F.countDistinct(\"customer_id\").alias(\"unique_customers\"))\n",
    ")\n",
    "\n",
    "# 3) –°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞\n",
    "avg_check_per_customer = (\n",
    "    fact_sales\n",
    "      .groupBy(\"customer_id\")\n",
    "      .agg((F.sum(\"total_price\")/F.count(\"*\")).alias(\"avg_check\"))\n",
    ")\n",
    "\n",
    "for tbl, df, order_cols in [\n",
    "    (\"top10_customers\",        top10_customers,        [\"total_spent\"]),\n",
    "    (\"customers_by_country\",   customers_by_country,   [\"country_name\"]),\n",
    "    (\"avg_check_per_customer\", avg_check_per_customer, [\"customer_id\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4d9875-8adc-4f76-b260-579e32fd802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è monthly_trends: 12 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è yearly_revenue: 1 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è avg_order_size_by_month: 12 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 5a: sales_by_time ‚Äî –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "# 1) –ú–µ—Å—è—á–Ω—ã–µ –∏ –≥–æ–¥–æ–≤—ã–µ —Ç—Ä–µ–Ω–¥—ã –ø—Ä–æ–¥–∞–∂\n",
    "monthly_trends = (\n",
    "    fact_sales\n",
    "      .join(dim_dates.withColumnRenamed(\"full_date\",\"sale_date\"), \"date_id\")\n",
    "      .withColumn(\"year\",  F.year(\"sale_date\"))\n",
    "      .withColumn(\"month\", F.month(\"sale_date\"))\n",
    "      .groupBy(\"year\",\"month\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    ")\n",
    "\n",
    "# 2) –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≤—ã—Ä—É—á–∫–∏ –∑–∞ —Ä–∞–∑–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä –≥–æ–¥ –∫ –≥–æ–¥—É)\n",
    "yearly_revenue = (\n",
    "    monthly_trends\n",
    "      .groupBy(\"year\")\n",
    "      .agg(F.sum(\"revenue\").alias(\"yearly_revenue\"))\n",
    ")\n",
    "\n",
    "# 3) –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∑–∞–∫–∞–∑–∞ –ø–æ –º–µ—Å—è—Ü–∞–º\n",
    "avg_order_size_by_month = (\n",
    "    fact_sales\n",
    "      .join(dim_dates.withColumnRenamed(\"full_date\",\"sale_date\"), \"date_id\")\n",
    "      .withColumn(\"year\",  F.year(\"sale_date\"))\n",
    "      .withColumn(\"month\", F.month(\"sale_date\"))\n",
    "      .groupBy(\"year\",\"month\")\n",
    "      .agg((F.sum(\"total_price\")/F.count(\"*\")).alias(\"avg_order_size\"))\n",
    ")\n",
    "\n",
    "for tbl, df, order_cols in [\n",
    "    (\"monthly_trends\",          monthly_trends,          [\"year\",\"month\"]),\n",
    "    (\"yearly_revenue\",          yearly_revenue,          [\"year\"]),\n",
    "    (\"avg_order_size_by_month\", avg_order_size_by_month, [\"year\",\"month\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d716b07-372d-46b6-aa40-8d0d5361abda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è top5_stores: 5 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è sales_by_city_country: 383 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è avg_check_per_store: 383 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 6a: sales_by_store ‚Äî –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "# 1) –¢–æ–ø-5 –º–∞–≥–∞–∑–∏–Ω–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ\n",
    "top5_stores = (\n",
    "    fact_sales\n",
    "      .join(dim_stores, \"store_id\")\n",
    "      .groupBy(\"store_id\",\"store_name\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    "      .orderBy(F.col(\"revenue\").desc())\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "# 2) –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ –ø–æ –≥–æ—Ä–æ–¥–∞–º –∏ —Å—Ç—Ä–∞–Ω–∞–º\n",
    "sales_by_city_country = (\n",
    "    fact_sales\n",
    "      .join(dim_stores, \"store_id\")\n",
    "      .join(dim_cities,    [\"city_id\"],    \"left\")\n",
    "      .join(dim_countries, [\"country_id\"], \"left\")\n",
    "      .groupBy(\"city_name\",\"country_name\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    ")\n",
    "\n",
    "# 3) –°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞–≥–∞–∑–∏–Ω–∞\n",
    "avg_check_per_store = (\n",
    "    fact_sales\n",
    "      .groupBy(\"store_id\")\n",
    "      .agg((F.sum(\"total_price\")/F.count(\"*\")).alias(\"avg_check\"))\n",
    ")\n",
    "\n",
    "for tbl, df, order_cols in [\n",
    "    (\"top5_stores\",           top5_stores,           [\"revenue\"]),\n",
    "    (\"sales_by_city_country\", sales_by_city_country, [\"city_name\"]),\n",
    "    (\"avg_check_per_store\",   avg_check_per_store,   [\"store_id\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21307c4b-190f-49e4-99f2-eb3bf942fb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è top5_suppliers: 3 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è avg_price_by_supplier: 3 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è sales_by_supplier_country: 3 —Å—Ç—Ä–æ–∫\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 7a: sales_by_supplier ‚Äî –≤—Å–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "# 1) –¢–æ–ø-5 –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤ –ø–æ –≤—ã—Ä—É—á–∫–µ\n",
    "sales_with_supp = fact_sales.join(dim_products.select(\"product_id\",\"supplier_id\"), \"product_id\")\n",
    "top5_suppliers = (\n",
    "    sales_with_supp\n",
    "      .groupBy(\"supplier_id\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    "      .orderBy(F.col(\"revenue\").desc())\n",
    "      .limit(5)\n",
    ")\n",
    "\n",
    "# 2) –°—Ä–µ–¥–Ω—è—è —Ü–µ–Ω–∞ —Ç–æ–≤–∞—Ä–æ–≤ –æ—Ç –∫–∞–∂–¥–æ–≥–æ –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞\n",
    "avg_price_by_supplier = (\n",
    "    sales_with_supp\n",
    "      .groupBy(\"supplier_id\")\n",
    "      .agg((F.sum(\"total_price\")/F.sum(\"quantity\")).alias(\"avg_price\"))\n",
    ")\n",
    "\n",
    "# 3) –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–æ–¥–∞–∂ –ø–æ —Å—Ç—Ä–∞–Ω–∞–º –ø–æ—Å—Ç–∞–≤—â–∏–∫–æ–≤\n",
    "sales_by_supplier_country = (\n",
    "    sales_with_supp\n",
    "      .join(dim_suppliers, \"supplier_id\")\n",
    "      .join(dim_countries, [\"country_id\"], \"left\")\n",
    "      .groupBy(\"country_name\")\n",
    "      .agg(F.sum(\"total_price\").alias(\"revenue\"))\n",
    ")\n",
    "\n",
    "for tbl, df, order_cols in [\n",
    "    (\"top5_suppliers\",            top5_suppliers,            [\"revenue\"]),\n",
    "    (\"avg_price_by_supplier\",     avg_price_by_supplier,     [\"supplier_id\"]),\n",
    "    (\"sales_by_supplier_country\", sales_by_supplier_country, [\"country_name\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34d2823c-0489-4ae0-ba29-c61a61d570e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è highest_rating: 1 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è lowest_rating: 1 —Å—Ç—Ä–æ–∫\n",
      "‚úîÔ∏è most_reviewed: 3 —Å—Ç—Ä–æ–∫\n",
      "üßÆ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è rating‚Üîunits_sold = 0.0076\n"
     ]
    }
   ],
   "source": [
    "# –Ø—á–µ–π–∫–∞ 8a (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è): product_quality\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "quality = (\n",
    "    fact_sales\n",
    "      .join(dim_products, \"product_id\")\n",
    "      .select(\"product_id\",\"product_name\",\"rating\",\"reviews\",\"quantity\")\n",
    ")\n",
    "\n",
    "window_desc = Window.orderBy(F.col(\"rating\").desc())\n",
    "window_asc  = Window.orderBy(F.col(\"rating\").asc())\n",
    "\n",
    "highest_rating = (\n",
    "    quality\n",
    "      .withColumn(\"rn\", row_number().over(window_desc))\n",
    "      .filter(F.col(\"rn\") == 1)\n",
    "      .drop(\"rn\")\n",
    ")\n",
    "lowest_rating = (\n",
    "    quality\n",
    "      .withColumn(\"rn\", row_number().over(window_asc))\n",
    "      .filter(F.col(\"rn\") == 1)\n",
    "      .drop(\"rn\")\n",
    ")\n",
    "\n",
    "corr_val = quality.stat.corr(\"rating\",\"quantity\")\n",
    "\n",
    "most_reviewed = (\n",
    "    quality\n",
    "      .groupBy(\"product_id\",\"product_name\")\n",
    "      .agg(F.sum(\"reviews\").alias(\"total_reviews\"))\n",
    "      .orderBy(F.col(\"total_reviews\").desc())\n",
    "      .limit(10)\n",
    ")\n",
    "\n",
    "for tbl, df, order_cols in [\n",
    "    (\"highest_rating\", highest_rating, [\"rating\"]),\n",
    "    (\"lowest_rating\",  lowest_rating,  [\"rating\"]),\n",
    "    (\"most_reviewed\",  most_reviewed,  [\"total_reviews\"])\n",
    "]:\n",
    "    df.write.format(\"jdbc\") \\\n",
    "       .option(\"url\", ch_url).option(\"dbtable\", tbl) \\\n",
    "       .options(**{**ch_props, \"createTableOptions\":f\"ENGINE = MergeTree() ORDER BY ({','.join(order_cols)})\"}) \\\n",
    "       .mode(\"overwrite\").save()\n",
    "    print(f\"‚úîÔ∏è {tbl}: {df.count()} —Å—Ç—Ä–æ–∫\")\n",
    "\n",
    "print(f\"üßÆ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è rating‚Üîunits_sold = {corr_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4251ff19-5c73-4763-b1dd-1fd05fa76fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
