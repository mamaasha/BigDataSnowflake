{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c38829-6cae-4f3f-836e-39f7f532b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def clean_csv_record(line: str) -> str:\n",
    "    \"\"\"\n",
    "    Очищает строку CSV:\n",
    "    - Убирает лишние пробелы\n",
    "    - Убирает пробелы вокруг запятых и знака равенства\n",
    "    \"\"\"\n",
    "    line = line.rstrip('\\r\\n')\n",
    "    line = re.sub(r\"\\s{2,}\", \" \", line)\n",
    "    line = re.sub(r\"\\s*,\\s*\", \",\", line)\n",
    "    line = re.sub(r\"\\s*=\\s*\", \"=\", line)\n",
    "    return line\n",
    "\n",
    "\n",
    "def process_file(input_path: Path, output_path: Path) -> None:\n",
    "    \"\"\"\n",
    "    Читает input_path, соединяет разбитые записи и записывает очищенный CSV в output_path.\n",
    "    Каждая запись на отдельной строке, записи начинаются с числа.\n",
    "    \"\"\"\n",
    "    new_record = re.compile(r\"^\\d+,\")\n",
    "    output_lines = []\n",
    "    buffer = []\n",
    "\n",
    "    with input_path.open('r', encoding='utf-8') as fin:\n",
    "        for raw in fin:\n",
    "            cleaned = clean_csv_record(raw)\n",
    "            if new_record.match(cleaned):\n",
    "                if buffer:\n",
    "                    # добавляем накопленную запись\n",
    "                    output_lines.append(''.join(buffer))\n",
    "                buffer = [cleaned]\n",
    "            else:\n",
    "                buffer.append(cleaned)\n",
    "\n",
    "    if buffer:\n",
    "        output_lines.append(''.join(buffer))\n",
    "\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with output_path.open('w', encoding='utf-8', newline='\\n') as fout:\n",
    "        fout.write(\"\\n\".join(output_lines))\n",
    "\n",
    "\n",
    "def start_parsing():\n",
    "    raw_dir = Path('./исходные данные')\n",
    "    out_dir = Path('./после парсинга')\n",
    "    pattern = 'MOCK_DATA*.csv'\n",
    "\n",
    "    files = sorted(raw_dir.glob(pattern))\n",
    "    if not files:\n",
    "        print(f\"Нет файлов по шаблону {pattern} в {raw_dir}\")\n",
    "        return\n",
    "\n",
    "    for inp in files:\n",
    "        out_name = f\"parsed_mock{files.index(inp)+1}.csv\"\n",
    "        out_path = out_dir / out_name\n",
    "        print(f\"Обработка {inp} → {out_path}\")\n",
    "        process_file(inp, out_path)\n",
    "\n",
    "    print(\"Готово!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce21a315-e9ae-46ae-a4c8-cc194d9f2f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import psycopg2\n",
    "\n",
    "DB_PARAMS = {\n",
    "    \"host\":     os.getenv(\"DB_HOST\", \"localhost\"),\n",
    "    \"port\":     os.getenv(\"DB_PORT\", \"5432\"),\n",
    "    \"dbname\":   os.getenv(\"DB_NAME\", \"spark_db\"),\n",
    "    \"user\":     os.getenv(\"DB_USER\", \"spark_user\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\", \"spark_password\"),\n",
    "}\n",
    "\n",
    "conn = psycopg2.connect(**DB_PARAMS)\n",
    "cur = conn.cursor()\n",
    "\n",
    "CSV_DIR = os.getenv(\"CSV_DIR\", \".\")\n",
    "WORK_DIR = os.getenv(\"WORK_DIR\", \".\")\n",
    "\n",
    "def load_file_contents(path):\n",
    "    for enc in (\"utf-8-sig\", \"utf-8\", \"cp1251\", \"latin-1\"):\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc) as f:\n",
    "                return f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise UnicodeDecodeError(f\"Не удалось прочитать файл {path} в поддерживаемой кодировке\")\n",
    "\n",
    "def init_db():\n",
    "    ddl_path = os.path.join(WORK_DIR, \"init.sql\")\n",
    "    ddl_sql = load_file_contents(ddl_path)\n",
    "    cur.execute(ddl_sql)\n",
    "    conn.commit()\n",
    "    print(\"DDL выполнен\")\n",
    "\n",
    "def load_data():\n",
    "    pattern = os.path.join(CSV_DIR, \"./после парсинга/parsed_mock*.csv\")\n",
    "    files = sorted(glob.glob(pattern))\n",
    "    for path in files:\n",
    "        print(f\"Загрузка {path}\")\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            cur.copy_expert(\"COPY mock_data FROM STDIN WITH CSV HEADER\", f)\n",
    "    conn.commit()\n",
    "    print(\"CSV загружены в mock_data\")\n",
    "\n",
    "def load():\n",
    "    init_db()\n",
    "    load_data()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
